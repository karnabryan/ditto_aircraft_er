{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook overview\n",
    "\n",
    "This notebook explores tokenization and embeddings with Hugging Face transformers (BERT/DistilBERT) and PyTorch. It demonstrates how to inspect token ids, embedding tables, raw input embeddings, and contextual embeddings, and how to build simple sentence embeddings.\n",
    "\n",
    "## High-level flow\n",
    "- Check PyTorch/CUDA availability and GPU name (cell 1).\n",
    "- Tokenize a long domain-specific string with `BertTokenizerFast` and inspect tokens/ids (cell 2). The variables `text`, `tok`, and `out` come from here:\n",
    "    - `text`: the input string\n",
    "    - `tok`: the loaded `BertTokenizerFast`\n",
    "    - `out`: the tokenization result (`BatchEncoding` with `input_ids`)\n",
    "- Load `DistilBertModel` and access its embedding weight matrices (word & position) (cell 3).\n",
    "- Inspect single elements of the embedding matrices (cells 4 and 5).\n",
    "- Load tokenizer + DistilBERT, move model to device, create a small batch of example texts, and tokenize them into `enc` tensors on device (cell 6).\n",
    "- Show tokenization for the first example text (cell 7).\n",
    "- Run a forward pass to get `last_hidden_state` (contextual per-token embeddings), compute attention-masked mean pooling to get sentence embeddings, retrieve raw input embeddings via `model.get_input_embeddings()(input_ids)`, and map ids back to token strings (cell 8). Example: print token strings and inspect a particular token embedding.\n",
    "- Demonstrate how to compute raw input embedding sum h0 = word_emb + pos_emb and compare it to `model.embeddings(...)` which includes LayerNorm+Dropout (cell 9).\n",
    "\n",
    "## Key concepts shown\n",
    "- Tokenization → input ids, special tokens ([CLS], [SEP], [PAD]).\n",
    "- Embedding tables:\n",
    "    - Word embeddings: lookup of token ids → vectors.\n",
    "    - Position embeddings: absolute position ids → vectors.\n",
    "- Raw input embeddings (word + position) vs. contextual embeddings (outputs of Transformer layers).\n",
    "- Masked mean pooling to obtain fixed-size sentence embeddings.\n",
    "- Moving tensors and model to GPU if available.\n",
    "\n",
    "## How to reuse\n",
    "- `tok` and `out` are available in the notebook and can be reused directly.\n",
    "- `enc` produced in cell 6 contains tensors used for forward passes.\n",
    "- `model` (DistilBertModel) and its embedding tables are available after their respective cells; avoid re-importing or reloading unless you intend to overwrite them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding BERT Embeddings\n",
    "This notebook explores how tokenization and embeddings work with Hugging Face transformers (BERT/DistilBERT) and PyTorch. \n",
    "\n",
    "It provides examples for how to inspect token ids, embedding tables, raw input embeddings, and contextual embeddings, and how to build simple sentence embeddings using the torch library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbryan/miniconda3/envs/ditto312/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import BertTokenizerFast, DistilBertTokenizerFast, DistilBertModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.5.1\n",
      "CUDA available: True\n",
      "Torch CUDA runtime: 12.4\n",
      "cuDNN: 90100\n",
      "GPU: NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "## Check PyTorch/CUDA availability and GPU name\n",
    "## This will print the installed PyTorch version, CUDA availability, and GPU name if available.\n",
    " \n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Torch CUDA runtime:\", torch.version.cuda)\n",
    "print(\"cuDNN:\", torch.backends.cudnn.version())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert Tokenization\n",
    "\n",
    "- Tokenize a string with `BertTokenizerFast` and inspect tokens/ids.    \n",
    "    - `text`: the input string\n",
    "    - `tok`: the loaded `BertTokenizerFast`\n",
    "    - `out`: the tokenization result (`BatchEncoding` with `input_ids`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text: COL cictt_make VAL AERO COMMANDER COL cictt_model VAL 690 COL cictt_series VAL UNDESIGNATED SERIES\tCOL make VAL CE COL model VAL 180 COL series VAL 180\n",
      "Tokens: ['[CLS]', 'col', 'ci', '##ct', '##t', '_', 'make', 'val', 'aero', 'commander', 'col', 'ci', '##ct', '##t', '_', 'model', 'val', '690', 'col', 'ci', '##ct', '##t', '_', 'series', 'val', 'und', '##es', '##ign', '##ated', 'series', 'col', 'make', 'val', 'ce', 'col', 'model', 'val', '180', 'col', 'series', 'val', '180', '[SEP]']\n",
      "Token IDs: [101, 8902, 25022, 6593, 2102, 1035, 2191, 11748, 18440, 3474, 8902, 25022, 6593, 2102, 1035, 2944, 11748, 28066, 8902, 25022, 6593, 2102, 1035, 2186, 11748, 6151, 2229, 23773, 4383, 2186, 8902, 2191, 11748, 8292, 8902, 2944, 11748, 8380, 8902, 2186, 11748, 8380, 102]\n",
      "Number of tokens: 43\n"
     ]
    }
   ],
   "source": [
    "# Bert Tokenization\n",
    "tok = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "text = \"COL cictt_make VAL AERO COMMANDER COL cictt_model VAL 690 COL cictt_series VAL UNDESIGNATED SERIES\\tCOL make VAL CE COL model VAL 180 COL series VAL 180\"\n",
    "out = tok(text, return_attention_mask=False, return_token_type_ids=False)\n",
    "print(\"Input Text:\", text)\n",
    "print(\"Tokens:\",tok.convert_ids_to_tokens(out[\"input_ids\"]))\n",
    "print(\"Token IDs:\", out[\"input_ids\"])\n",
    "print(\"Number of tokens:\", len(out[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained Bert Model (distlbert-base-uncased)\n",
    "- Embedding tables:\n",
    "    - Ew - Word embeddings: lookup of token ids → vectors (30522 token ids to 768 dimensions).\n",
    "    - Ep - Position embeddings: absolute position ids → vectors ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Ew: torch.Size([30522, 768]) , Shape Ep: torch.Size([512, 768])\n"
     ]
    }
   ],
   "source": [
    "# Load `DistilBertModel` and inspect embedding weight matrices\n",
    "m = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "# Embedding weight matrices (word)\n",
    "Ew = m.embeddings.word_embeddings.weight        # [30522, 768]\n",
    "# Embedding weight matrices (position)\n",
    "Ep = m.embeddings.position_embeddings.weight    # [512, 768]\n",
    "print(\"Shape Ew:\", Ew.shape, \", Shape Ep:\", Ep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0166, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect single elements of the embedding matrices\n",
    "Ew[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0175, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect single elements of the embedding matrices\n",
    "Ep[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenizer and model\n",
    "Load tokenizer + DistilBERT, move model to device, create a small batch of example texts, and tokenize them into `enc` tensors on device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B (batch size):  2\n",
      "L (sequence3 length in tokens):  43\n",
      "H: (hidden size) 768\n",
      "Input shape: torch.Size([2, 43])\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer + DistilBERT, move model to device, create a small batch of example texts, and tokenize them into `enc` tensors on device\n",
    "\n",
    "# 1) Load tokenizer + model\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "model.eval()\n",
    "\n",
    "# Check GPU:\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 2) Example text (can be a list for batching)\n",
    "texts = [\n",
    "    \"COL cictt_make VAL AERO COMMANDER COL cictt_model VAL 690 COL cictt_series VAL UNDESIGNATED SERIES\\tCOL make VAL CE COL model VAL 180 COL series VAL 180\", \n",
    "    \"COL cictt_make VAL BOEING COL cictt_model VAL 737 COL cictt_series VAL 7V3\tCOL make VAL DH COL model VAL 104 COL series VAL 7A\"\n",
    "]\n",
    "\n",
    "# 3) Tokenize\n",
    "enc = tokenizer(\n",
    "    texts,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")\n",
    "enc = {k: v.to(device) for k, v in enc.items()}  # move to device\n",
    "\n",
    "\n",
    "# Inspect batch size B, sequence length L, hidden size H\n",
    "input_ids = enc[\"input_ids\"].to(device)          # [B, L]\n",
    "B, L = input_ids.shape\n",
    "H = model.config.dim                              # 768\n",
    "\n",
    "print(\"Input shape:\", input_ids.shape)\n",
    "print(\"B (batch size): \", B)\n",
    "print(\"L (sequence length in tokens): \", L)\n",
    "print(\"H: (hidden size)\", H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Hidden shape: torch.Size([2, 43, 768])\n"
     ]
    }
   ],
   "source": [
    "# Run a forward pass to get `last_hidden_state` (contextual per-token embeddings)\n",
    "\n",
    "# 4) Forward pass → contextual token embeddings (last hidden state)\n",
    "#    Shape: [batch_size, seq_len, hidden_size]\n",
    "with torch.no_grad():\n",
    "    outputs = model(**enc)\n",
    "last_hidden = outputs.last_hidden_state  # contextual embeddings\n",
    "\n",
    "print(\"Last Hidden shape:\", last_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens for item 0:\n",
      " ['[CLS]', 'col', 'ci', '##ct', '##t', '_', 'make', 'val', 'aero', 'commander', 'col', 'ci', '##ct', '##t', '_', 'model', 'val', '690', 'col', 'ci', '##ct', '##t', '_', 'series', 'val', 'und', '##es', '##ign', '##ated', 'series', 'col', 'make', 'val', 'ce', 'col', 'model', 'val', '180', 'col', 'series', 'val', '180', '[SEP]']\n",
      "Tokens for item 0:\n",
      " ['[CLS]', 'col', 'ci', '##ct', '##t', '_', 'make', 'val', 'boeing', 'col', 'ci', '##ct', '##t', '_', 'model', 'val', '737', 'col', 'ci', '##ct', '##t', '_', 'series', 'val', '7', '##v', '##3', 'col', 'make', 'val', 'dh', 'col', 'model', 'val', '104', 'col', 'series', 'val', '7', '##a', '[SEP]', '[PAD]', '[PAD]']\n",
      "Per-token contextual embeddings shape: torch.Size([2, 43, 768])\n",
      "Sentence embedding shape: torch.Size([2, 768])\n",
      "Token[10]: col\n",
      "Embedding vector (last hidden) shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "# Compute attention-masked mean pooling to get sentence embeddings, \n",
    "# retrieve raw input embeddings via `model.get_input_embeddings()(input_ids)`, and \n",
    "# map ids back to token strings\n",
    "# Print token strings and inspect a particular token embedding.\n",
    "\n",
    "\n",
    "# 5) Build a sentence embedding (attention-masked mean pooling)\n",
    "#    This averages only over real tokens (excludes padding).\n",
    "attn = enc[\"attention_mask\"].unsqueeze(-1)            # [B, L, 1]\n",
    "summed = (last_hidden * attn).sum(dim=1)              # [B, H]\n",
    "counts = attn.sum(dim=1).clamp(min=1)                 # [B, 1]\n",
    "sentence_embeddings = summed / counts                 # [B, H]\n",
    "\n",
    "# 6) Optional: raw input embeddings (lookup table before Transformer layers)\n",
    "#    These are *not* contextual; they’re the embedding matrix rows for your tokens.\n",
    "with torch.no_grad():\n",
    "    input_embeds = model.get_input_embeddings()(enc[\"input_ids\"])  # [B, L, H]\n",
    "\n",
    "# 7) Map back to tokens if you want to line up embeddings with strings:\n",
    "tokens = [tokenizer.convert_ids_to_tokens(ids) for ids in enc[\"input_ids\"].tolist()]\n",
    "\n",
    "# ---- Examples of how to use the results ----\n",
    "print(\"Tokens for item 0:\\n\", tokens[0])\n",
    "print(\"Tokens for item 0:\\n\", tokens[1])\n",
    "print(\"Per-token contextual embeddings shape:\", last_hidden.shape)\n",
    "print(\"Sentence embedding shape:\", sentence_embeddings.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Access the embedding for, say, the 10th token in the sequence (0-based):\n",
    "b, t = 0, 10\n",
    "print(\"Token[10]:\", tokens[b][t])\n",
    "print(\"Embedding vector (last hidden) shape:\", last_hidden[b, t].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B (batch size):  2\n",
      "L (sequence3 length in tokens):  13\n",
      "H: (hidden size) 768\n",
      "torch.Size([2, 13, 768]) torch.Size([2, 13, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Demonstrate how to compute raw input embedding sum h0 = word_emb + pos_emb and compare it to `model.embeddings(...)` which includes LayerNorm+Dropout (cell 9).\n",
    "\n",
    "# 1) Load tokenizer + model\n",
    "tok = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\").eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 2) Example inputs (batch of 2)\n",
    "texts = [\n",
    "    \"hello world\",\n",
    "    \"Smoke was detected in the cabin on a Boeing 737.\"\n",
    "]\n",
    "enc = tok(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "input_ids = enc[\"input_ids\"].to(device)          # [B, L]\n",
    "B, L = input_ids.shape\n",
    "H = model.config.dim                              # 768\n",
    "\n",
    "print(\"B (batch size): \", B)\n",
    "print(\"L (sequence3 length in tokens): \", L)\n",
    "print(\"H: (hidden size)\", H)\n",
    "# 3) Lookup word and position embeddings\n",
    "Ew_table = model.embeddings.word_embeddings       # nn.Embedding[V, H]\n",
    "Ep_table = model.embeddings.position_embeddings   # nn.Embedding[512, H]\n",
    "\n",
    "E_word = Ew_table(input_ids)                      # [B, L, H]\n",
    "\n",
    "# DistilBERT uses absolute position ids 0..L-1 per sequence\n",
    "position_ids = torch.arange(L, device=device).unsqueeze(0).expand(B, L)  # [B, L]\n",
    "E_pos = Ep_table(position_ids)                    # [B, L, H]\n",
    "\n",
    "# 4) Raw embedding sum (this is h0 before LayerNorm/Dropout)\n",
    "h0 = E_word + E_pos                               # [B, L, H]\n",
    "\n",
    "# (Optional) Compare to the model’s embedding output (which adds LayerNorm+Dropout)\n",
    "with torch.no_grad():\n",
    "    h0_full = model.embeddings(input_ids=input_ids)  # [B, L, H]\n",
    "print(h0.shape, h0_full.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huggingface demo\n",
    "From here, this is from the huggingface demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2129, 2024, 2017, 1029, 102]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] how are you? [SEP]'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"How are you?\")\n",
    "print(encoded_input[\"input_ids\"])\n",
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598046541213989},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\n",
    "    [\n",
    "        \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "        \"I hate this so much!\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2026,  2878,  2166,  1012,   102],\n",
      "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 768])\n"
     ]
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutput(last_hidden_state=tensor([[[-0.1798,  0.2333,  0.6321,  ..., -0.3017,  0.5008,  0.1481],\n",
      "         [ 0.2758,  0.6497,  0.3200,  ..., -0.0760,  0.5136,  0.1329],\n",
      "         [ 0.9046,  0.0985,  0.2950,  ...,  0.3352, -0.1407, -0.6464],\n",
      "         ...,\n",
      "         [ 0.1466,  0.5661,  0.3235,  ..., -0.3376,  0.5100, -0.0561],\n",
      "         [ 0.7500,  0.0487,  0.1738,  ...,  0.4684,  0.0030, -0.6084],\n",
      "         [ 0.0519,  0.3729,  0.5223,  ...,  0.3584,  0.6500, -0.3883]],\n",
      "\n",
      "        [[-0.2937,  0.7283, -0.1497,  ..., -0.1187, -1.0227, -0.0422],\n",
      "         [-0.2206,  0.9384, -0.0951,  ..., -0.3643, -0.6605,  0.2407],\n",
      "         [-0.1536,  0.8988, -0.0728,  ..., -0.2189, -0.8528,  0.0710],\n",
      "         ...,\n",
      "         [-0.3017,  0.9002, -0.0200,  ..., -0.1082, -0.8412, -0.0861],\n",
      "         [-0.3338,  0.9674, -0.0729,  ..., -0.1952, -0.8181, -0.0634],\n",
      "         [-0.3454,  0.8824, -0.0426,  ..., -0.0993, -0.8329, -0.1065]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.5607,  1.6123],\n",
      "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0195e-02, 9.5980e-01],\n",
      "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"dtype\": \"float32\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"bert-base-cased\")\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.57.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig\n",
    "bert_config = BertConfig.from_pretrained(\"bert-base-cased\")\n",
    "print(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('directory_on_my_computer/tokenizer_config.json',\n",
       " 'directory_on_my_computer/special_tokens_map.json',\n",
       " 'directory_on_my_computer/vocab.txt',\n",
       " 'directory_on_my_computer/added_tokens.json')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"directory_on_my_computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ditto312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
